{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "안녕하세요, Colaboratory입니다",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sabumjung/DL-with-TensorFlow/blob/DL-with-TensorFlow/10%EC%9E%A5_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "o030agdzMBMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "565e91f0-058b-4a04-b4ea-9b3bd0d9b063"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.5)\r\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.5)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\r\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.13)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YP7KPQD9NzIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MtVRtakN5D1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# FrozenLake 환경 정의\n",
        "env = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2IcvrZdnN7H3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 텐서플로 플레이스홀더와 변수 설정\n",
        "tf.reset_default_graph()\n",
        "inputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\n",
        "W = tf.Variable(tf.random_uniform([16,4],0,0.01))\n",
        "Qout = tf.matmul(inputs1,W)\n",
        "predict = tf.argmax(Qout,1)\n",
        "nextQ = tf.placeholder(shape=[1,4],dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0TGWFtu1uCcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 손실함수와 최적화방법(GradnentDescentOptimizer) 정의 \n",
        "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
        "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "updateModel = trainer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Stf8de8SuMYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 변수 초기화\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXhNJ7HtuPfU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Q-Learning 파라미터 정의\n",
        "gamma = .99\n",
        "e = 0.1\n",
        "num_episodes = 6000\n",
        "jList = []\n",
        "rList = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LXPVEz5ulKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "853d19e5-e533-4001-add5-b6f0984e0575"
      },
      "cell_type": "code",
      "source": [
        "# Sess실행 및 변수초기화 실시\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # Q-Learning 시작\n",
        "    for i in range(num_episodes):\n",
        "        s = env.reset()\n",
        "        rAll = 0\n",
        "        d = False\n",
        "        j = 0\n",
        "        while j < 99:\n",
        "            j+=1\n",
        "            # 여러개의 처리되는 텐서(predict, Qout)를 List로 처리\n",
        "            # session은 feed일 경우 feed_dict로 처리값을 할당해야 함\n",
        "            a,allQ = sess.run([predict,Qout],feed_dict= \\\n",
        "                              {inputs1:np.identity(16)[s:s+1]})\n",
        "            if np.random.rand(1) < e:\n",
        "                a[0] = env.action_space.sample()\n",
        "            s1,r,d,_ = env.step(a[0])\n",
        "            Q1 = sess.run(Qout,feed_dict=\\\n",
        "                          {inputs1:np.identity(16)[s1:s1+1]})\n",
        "            maxQ1 = np.max(Q1)\n",
        "            targetQ = allQ\n",
        "            targetQ[0,a[0]] = r + gamma *maxQ1\n",
        "            _,W1 = sess.run([updateModel,W],\\\n",
        "                            feed_dict=\\\n",
        "                           {inputs1:np.identity(16)[s:s+1],nextQ:targetQ})\n",
        "# 총보상 합산\n",
        "            rAll += r\n",
        "            s = s1\n",
        "            if d == True:\n",
        "                e = 1./((i/50) + 10)\n",
        "                break\n",
        "        jList.append(j)\n",
        "        rList.append(rAll)\n",
        "# 결과출력\n",
        "    print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")            "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of succesful episodes: 0.579%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}