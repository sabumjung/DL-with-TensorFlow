{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "안녕하세요, Colaboratory입니다",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sabumjung/DL-with-TensorFlow/blob/DL-with-TensorFlow/10%EC%9E%A5_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "o030agdzMBMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d8dcc93a-166a-4018-ebcb-54f4a3bd12d5"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 11.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/cb/14/71/f4ab006b1e6ff75c2b54985c2f98d0644fffe9c1dddc670925\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.5 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YP7KPQD9NzIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MtVRtakN5D1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2IcvrZdnN7H3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "732eaa8f-c51c-4406-9b99-f4e8df223c19"
      },
      "cell_type": "code",
      "source": [
        "# 강화학습 대상 테이블 초기화(0으로 설정)\n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "\n",
        "# 학습 파라미터 설정(학습률, 감마, 에피소드 개수)\n",
        "# 감마 : discount factor으로 상태가치를 계산하는데 있어 미래의 보상을 얼마나 가치있게 고려할지 설정하는 값\n",
        "# V(s)=E(R_t+1+gamma*R_t+2+gamma^2*R_t+3+ ...|S_t=s)\n",
        "# 감마값은 0~1의 값을 부여함, 0(t+1만을 보상), 1(t+1을 포함한 전체 미래의 보상을 동일하게 보상)\n",
        "lr = .85\n",
        "# 감마값을 0.99로 설정함(t+1의 보상은 그대로, t+2의 보상은 0.99를 곱한 결과를 합산하여 계산함 )\n",
        "gamma = .99\n",
        "num_episodes = 2000\n",
        "\n",
        "# 에피소드별로 총 보상(rewards)와 단계(steps) 정보를 갖는 리스트를 만든다.\n",
        "rList = []\n",
        "\n",
        "# 2000 에피소드를 수행한다.\n",
        "for i in range(num_episodes):\n",
        "\n",
        "# 매 에피소드마다 환경을 재설정(reset)하고 첫번째 신규 관측값을 가져온다.\n",
        "    s = env.reset()\n",
        "    rAll = 0\n",
        "    d = False\n",
        "    j = 0\n",
        "\n",
        "   # Q-Table 학습 알고리즘\n",
        "    while j < 99:\n",
        "        j+=1\n",
        "\n",
        "  # Q-Table에서 탐욕적으로 한가지 행동을 선택한다.\n",
        "        a = np.argmax(Q[s,:]+ \\\n",
        "                  np.random.randn(1, env.action_space.n)*(1./(i+1)))\n",
        "\n",
        "  # 환경으로부터 신규 상태와 보상을 가져옮\n",
        "  # 예) t에서 s(t)일때 a(t)실행시, t+1의 s(t+1)와 r(t+1)을 가져옮\n",
        "        s1,r,d,_ = env.step(a)\n",
        "\n",
        "        # 새로운 학습지식을 이용하여 Q-Table을 업데이트한다.\n",
        "        Q[s,a] = Q[s,a] + lr*(r + gamma *np.max(Q[s1,:]) - Q[s,a])\n",
        "        rAll += r\n",
        "        s = s1\n",
        "        if d == True:\n",
        "            break\n",
        "\n",
        "    rList.append(rAll)\n",
        "\n",
        "print(\"Score over time: \" +  str(sum(rList)/num_episodes))\n",
        "print(\"Final Q-Table Values\")\n",
        "print(Q)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.6405\n",
            "Final Q-Table Values\n",
            "[[3.46337387e-03 3.96877616e-03 5.17902900e-01 2.53784196e-03]\n",
            " [3.17708951e-04 6.14926482e-04 3.23661992e-05 1.55125597e-01]\n",
            " [1.44661164e-03 4.31767370e-02 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.33889650e-01]\n",
            " [7.86296905e-01 1.93440942e-03 3.91992573e-04 5.60227354e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.08376869e-03 4.19097965e-04 1.00737986e-04 2.40367890e-06]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.81370572e-05 6.61304472e-04 2.56416710e-04 7.55875215e-01]\n",
            " [1.13995211e-03 3.06683242e-01 0.00000000e+00 0.00000000e+00]\n",
            " [8.49182801e-01 4.05431102e-04 3.20683231e-04 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.13962982e-02 0.00000000e+00 8.96442088e-01 0.00000000e+00]\n",
            " [0.00000000e+00 9.95228162e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}