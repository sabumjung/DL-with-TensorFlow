{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6장_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sabumjung/DL-with-TensorFlow/blob/DL-with-TensorFlow/6%EC%9E%A5_1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Gl1u9Hqs0uAl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdKi8K570wKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6cf8f9ef-75ec-4de3-819d-3eac308ab128"
      },
      "cell_type": "code",
      "source": [
        "# MNIST다운로드\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7_MPpQLe1dW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 신경명 훈련 파라미터 설정\n",
        "learning_rate = 0.001\n",
        "training_iters = 100000\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "# 신경망 구조 파라미터 설정\n",
        "n_input = 28 \n",
        "n_steps = 28 \n",
        "n_hidden = 128 \n",
        "n_classes = 10 \n",
        "\n",
        "# 플레이스홀더 설정\n",
        "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDPWMqrt1fMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 가중치, 바이어스 설정\n",
        "weights = {\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
        "}\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CzmbTzhi1iVw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RNN 정의\n",
        "def RNN(x, weights, biases):\n",
        "    x = tf.transpose(x, [1, 0, 2])\n",
        "    x = tf.reshape(x, [-1, n_input])\n",
        "    x = tf.split(axis=0, num_or_size_splits=n_steps, value=x)\n",
        "    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
        "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FfoGsW_p1kF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "451ef18c-cd05-456c-9079-cf4bddcbbfcf"
      },
      "cell_type": "code",
      "source": [
        "# 예측값 변수 설정\n",
        "pred = RNN(x, weights, biases)  \n",
        "\n",
        "# 손실함수, 최적화 방법 설정\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# 정확도 계산\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# 변수초기화\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-64c693c0f1ea>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vw0ecHlB1l7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1457
        },
        "outputId": "16f8e0d0-05d2-4163-9849-a44d7a78eaf1"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    step = 1\n",
        "    while step * batch_size < training_iters:\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
        "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
        "        if step % display_step == 0:\n",
        "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
        "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
        "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.5f}\".format(acc))\n",
        "        step += 1\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    test_len = 128\n",
        "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
        "    test_label = mnist.test.labels[:test_len]\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 1280, Minibatch Loss= 1.857771, Training Accuracy= 0.39062\n",
            "Iter 2560, Minibatch Loss= 1.476976, Training Accuracy= 0.50781\n",
            "Iter 3840, Minibatch Loss= 1.310727, Training Accuracy= 0.61719\n",
            "Iter 5120, Minibatch Loss= 1.257023, Training Accuracy= 0.62500\n",
            "Iter 6400, Minibatch Loss= 0.871910, Training Accuracy= 0.70312\n",
            "Iter 7680, Minibatch Loss= 0.848903, Training Accuracy= 0.75000\n",
            "Iter 8960, Minibatch Loss= 0.837333, Training Accuracy= 0.72656\n",
            "Iter 10240, Minibatch Loss= 0.752596, Training Accuracy= 0.74219\n",
            "Iter 11520, Minibatch Loss= 0.495613, Training Accuracy= 0.78906\n",
            "Iter 12800, Minibatch Loss= 0.461555, Training Accuracy= 0.82812\n",
            "Iter 14080, Minibatch Loss= 0.388727, Training Accuracy= 0.89062\n",
            "Iter 15360, Minibatch Loss= 0.483160, Training Accuracy= 0.82031\n",
            "Iter 16640, Minibatch Loss= 0.478991, Training Accuracy= 0.85938\n",
            "Iter 17920, Minibatch Loss= 0.374286, Training Accuracy= 0.85938\n",
            "Iter 19200, Minibatch Loss= 0.278260, Training Accuracy= 0.93750\n",
            "Iter 20480, Minibatch Loss= 0.364057, Training Accuracy= 0.87500\n",
            "Iter 21760, Minibatch Loss= 0.327011, Training Accuracy= 0.87500\n",
            "Iter 23040, Minibatch Loss= 0.349441, Training Accuracy= 0.90625\n",
            "Iter 24320, Minibatch Loss= 0.429687, Training Accuracy= 0.90625\n",
            "Iter 25600, Minibatch Loss= 0.212811, Training Accuracy= 0.94531\n",
            "Iter 26880, Minibatch Loss= 0.189815, Training Accuracy= 0.93750\n",
            "Iter 28160, Minibatch Loss= 0.172447, Training Accuracy= 0.94531\n",
            "Iter 29440, Minibatch Loss= 0.175354, Training Accuracy= 0.92969\n",
            "Iter 30720, Minibatch Loss= 0.202394, Training Accuracy= 0.93750\n",
            "Iter 32000, Minibatch Loss= 0.239837, Training Accuracy= 0.90625\n",
            "Iter 33280, Minibatch Loss= 0.118571, Training Accuracy= 0.95312\n",
            "Iter 34560, Minibatch Loss= 0.299085, Training Accuracy= 0.89062\n",
            "Iter 35840, Minibatch Loss= 0.297405, Training Accuracy= 0.91406\n",
            "Iter 37120, Minibatch Loss= 0.270390, Training Accuracy= 0.92188\n",
            "Iter 38400, Minibatch Loss= 0.150117, Training Accuracy= 0.94531\n",
            "Iter 39680, Minibatch Loss= 0.183400, Training Accuracy= 0.93750\n",
            "Iter 40960, Minibatch Loss= 0.219298, Training Accuracy= 0.92188\n",
            "Iter 42240, Minibatch Loss= 0.229026, Training Accuracy= 0.94531\n",
            "Iter 43520, Minibatch Loss= 0.095080, Training Accuracy= 0.96875\n",
            "Iter 44800, Minibatch Loss= 0.195384, Training Accuracy= 0.92969\n",
            "Iter 46080, Minibatch Loss= 0.138121, Training Accuracy= 0.94531\n",
            "Iter 47360, Minibatch Loss= 0.134293, Training Accuracy= 0.95312\n",
            "Iter 48640, Minibatch Loss= 0.146418, Training Accuracy= 0.95312\n",
            "Iter 49920, Minibatch Loss= 0.153791, Training Accuracy= 0.94531\n",
            "Iter 51200, Minibatch Loss= 0.196627, Training Accuracy= 0.92969\n",
            "Iter 52480, Minibatch Loss= 0.171020, Training Accuracy= 0.92969\n",
            "Iter 53760, Minibatch Loss= 0.121337, Training Accuracy= 0.96875\n",
            "Iter 55040, Minibatch Loss= 0.121119, Training Accuracy= 0.95312\n",
            "Iter 56320, Minibatch Loss= 0.175407, Training Accuracy= 0.91406\n",
            "Iter 57600, Minibatch Loss= 0.158010, Training Accuracy= 0.95312\n",
            "Iter 58880, Minibatch Loss= 0.079901, Training Accuracy= 0.98438\n",
            "Iter 60160, Minibatch Loss= 0.116902, Training Accuracy= 0.96875\n",
            "Iter 61440, Minibatch Loss= 0.226871, Training Accuracy= 0.93750\n",
            "Iter 62720, Minibatch Loss= 0.130587, Training Accuracy= 0.94531\n",
            "Iter 64000, Minibatch Loss= 0.144331, Training Accuracy= 0.96094\n",
            "Iter 65280, Minibatch Loss= 0.127101, Training Accuracy= 0.95312\n",
            "Iter 66560, Minibatch Loss= 0.182030, Training Accuracy= 0.93750\n",
            "Iter 67840, Minibatch Loss= 0.084219, Training Accuracy= 0.96875\n",
            "Iter 69120, Minibatch Loss= 0.108999, Training Accuracy= 0.96875\n",
            "Iter 70400, Minibatch Loss= 0.092897, Training Accuracy= 0.96875\n",
            "Iter 71680, Minibatch Loss= 0.123453, Training Accuracy= 0.96094\n",
            "Iter 72960, Minibatch Loss= 0.134049, Training Accuracy= 0.96094\n",
            "Iter 74240, Minibatch Loss= 0.186310, Training Accuracy= 0.94531\n",
            "Iter 75520, Minibatch Loss= 0.099384, Training Accuracy= 0.96875\n",
            "Iter 76800, Minibatch Loss= 0.071391, Training Accuracy= 0.98438\n",
            "Iter 78080, Minibatch Loss= 0.118609, Training Accuracy= 0.98438\n",
            "Iter 79360, Minibatch Loss= 0.119326, Training Accuracy= 0.96094\n",
            "Iter 80640, Minibatch Loss= 0.066819, Training Accuracy= 0.98438\n",
            "Iter 81920, Minibatch Loss= 0.108791, Training Accuracy= 0.96875\n",
            "Iter 83200, Minibatch Loss= 0.170630, Training Accuracy= 0.94531\n",
            "Iter 84480, Minibatch Loss= 0.089097, Training Accuracy= 0.97656\n",
            "Iter 85760, Minibatch Loss= 0.091692, Training Accuracy= 0.97656\n",
            "Iter 87040, Minibatch Loss= 0.132006, Training Accuracy= 0.96094\n",
            "Iter 88320, Minibatch Loss= 0.143671, Training Accuracy= 0.95312\n",
            "Iter 89600, Minibatch Loss= 0.042046, Training Accuracy= 0.99219\n",
            "Iter 90880, Minibatch Loss= 0.055158, Training Accuracy= 0.98438\n",
            "Iter 92160, Minibatch Loss= 0.103943, Training Accuracy= 0.94531\n",
            "Iter 93440, Minibatch Loss= 0.107011, Training Accuracy= 0.96875\n",
            "Iter 94720, Minibatch Loss= 0.108537, Training Accuracy= 0.95312\n",
            "Iter 96000, Minibatch Loss= 0.173675, Training Accuracy= 0.95312\n",
            "Iter 97280, Minibatch Loss= 0.252593, Training Accuracy= 0.95312\n",
            "Iter 98560, Minibatch Loss= 0.104518, Training Accuracy= 0.98438\n",
            "Iter 99840, Minibatch Loss= 0.104253, Training Accuracy= 0.98438\n",
            "Optimization Finished!\n",
            "('Testing Accuracy:', 0.9921875)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_uLQNI271qAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}